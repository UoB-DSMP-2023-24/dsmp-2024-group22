{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "            max_price  min_price  open_price  close_price\ndate                                                     \n2025-01-02      303.0      243.0       267.0        288.0\n2025-01-03      317.0      270.0       281.0        291.0\n2025-01-04        NaN        NaN         NaN          NaN\n2025-01-05        NaN        NaN         NaN          NaN\n2025-01-06      346.0      276.0       278.0        327.0\n...               ...        ...         ...          ...\n2025-06-27      113.0       93.0       106.0        111.0\n2025-06-28        NaN        NaN         NaN          NaN\n2025-06-29        NaN        NaN         NaN          NaN\n2025-06-30      113.0       93.0       103.0        110.0\n2025-07-01      114.0       93.0        94.0        107.0\n\n[181 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>max_price</th>\n      <th>min_price</th>\n      <th>open_price</th>\n      <th>close_price</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2025-01-02</th>\n      <td>303.0</td>\n      <td>243.0</td>\n      <td>267.0</td>\n      <td>288.0</td>\n    </tr>\n    <tr>\n      <th>2025-01-03</th>\n      <td>317.0</td>\n      <td>270.0</td>\n      <td>281.0</td>\n      <td>291.0</td>\n    </tr>\n    <tr>\n      <th>2025-01-04</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2025-01-05</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2025-01-06</th>\n      <td>346.0</td>\n      <td>276.0</td>\n      <td>278.0</td>\n      <td>327.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2025-06-27</th>\n      <td>113.0</td>\n      <td>93.0</td>\n      <td>106.0</td>\n      <td>111.0</td>\n    </tr>\n    <tr>\n      <th>2025-06-28</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2025-06-29</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2025-06-30</th>\n      <td>113.0</td>\n      <td>93.0</td>\n      <td>103.0</td>\n      <td>110.0</td>\n    </tr>\n    <tr>\n      <th>2025-07-01</th>\n      <td>114.0</td>\n      <td>93.0</td>\n      <td>94.0</td>\n      <td>107.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>181 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"E:\\git\\dsmp-2024-group22\\data_preprocess\\DATA\\processed_tapes.csv\",index_col=\"date\")\n",
    "data.drop([\"Unnamed: 0\"],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['UoB_Set01_2025-01-02tapes.csv',\n 'UoB_Set01_2025-01-03tapes.csv',\n 'UoB_Set01_2025-01-06tapes.csv',\n 'UoB_Set01_2025-01-07tapes.csv',\n 'UoB_Set01_2025-01-08tapes.csv']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = r\"E:\\BRISTOL COURSE\\TB2\\mini project bristol\\JPMorgan_Set01\\Tapes\"\n",
    "file_ls = os.listdir(dir_path)  #get every name of the file\n",
    "file_ls[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "125"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_ls)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#found the max and min deal price\n",
    "def detailprice(name):\n",
    "    date = []\n",
    "    segments = []\n",
    "    tapes = pd.read_csv(r\"E:/BRISTOL COURSE/TB2/mini project bristol/JPMorgan_Set01/Tapes/\" + name + \"\", header=None,\n",
    "                        names=[\"Times\", \"price\", \"volume\"])\n",
    "    tapes['price'] = pd.to_numeric(tapes['price'], errors='coerce')\n",
    "    segment_size = len(tapes) // 100\n",
    "    data_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "    match = re.search(data_pattern, name)\n",
    "    date.append(match.group())\n",
    "    for i in range(50):\n",
    "        start_idx = i * segment_size\n",
    "        # 对于最后一个段，取所有剩余的数据点\n",
    "        end_idx = start_idx + segment_size if i < 49 else len(tapes)\n",
    "\n",
    "        segment = tapes.iloc[start_idx:end_idx]\n",
    "        max_price = segment['price'].max()\n",
    "        min_price = segment['price'].min()\n",
    "        open_price = segment['price'].iloc[0]\n",
    "        close_price = segment['price'].iloc[-1]\n",
    "        cumsum = segment[\"volume\"].sum()\n",
    "        segments.append({\n",
    "            'period': date[0] + f\"-{i + 1}\",\n",
    "            'max_price': max_price,\n",
    "            'min_price': min_price,\n",
    "            'open_price': open_price,\n",
    "            'close_price': close_price,\n",
    "            'Volume': cumsum\n",
    "        })\n",
    "        segments_df = pd.DataFrame(segments)\n",
    "    return segments_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#found the max and min deal price\n",
    "def detailVolume(name):\n",
    "    segments = []\n",
    "    tapes = pd.read_csv(r\"E:/BRISTOL COURSE/TB2/mini project bristol/JPMorgan_Set01/Tapes/\" + name + \"\", header=None,\n",
    "                        names=[\"Times\", \"price\", \"volume\"])\n",
    "    cumsum = tapes[\"volume\"].sum()\n",
    "    segments.append({'Volume': cumsum})\n",
    "    v_df = pd.DataFrame(segments)\n",
    "    return v_df\n",
    "\n",
    "result_df=pd.DataFrame(columns=['Volume'])\n",
    "df_list = []\n",
    "for i in file_ls:\n",
    "    segments_df = detailVolume(i)  # 调用detailprice函数处理每个文件\n",
    "    df_list.append(segments_df)  # 将结果添加到列表中\n",
    "# 在循环结束后，一次性拼接所有DataFrame\n",
    "volume_df = pd.concat(df_list, axis=0, ignore_index=True)  # 使用ignore_index=True重置索引\n",
    "# 现在 result_df 包含了所有文件处理后的数据，无需再创建新的DataFrame\n",
    "volume_df.to_csv(\"E:\\git\\dsmp-2024-group22\\data_preprocess\\DATA/tapes_volume.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "               period  max_price  min_price  open_price  close_price  Volume\n0        2025-01-02-1        270        250         267          266     458\n1        2025-01-02-2        269        249         263          261     497\n2        2025-01-02-3        269        249         264          261     446\n3        2025-01-02-4        269        248         268          266     462\n4        2025-01-02-5        270        250         269          255     466\n...               ...        ...        ...         ...          ...     ...\n12495   2025-07-01-96        113         93         105          107     552\n12496   2025-07-01-97        113         93         107          102     532\n12497   2025-07-01-98        112         93          93          112     537\n12498   2025-07-01-99        112         93         112          107     537\n12499  2025-07-01-100        113         98         106          107     678\n\n[12500 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>period</th>\n      <th>max_price</th>\n      <th>min_price</th>\n      <th>open_price</th>\n      <th>close_price</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-01-02-1</td>\n      <td>270</td>\n      <td>250</td>\n      <td>267</td>\n      <td>266</td>\n      <td>458</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-01-02-2</td>\n      <td>269</td>\n      <td>249</td>\n      <td>263</td>\n      <td>261</td>\n      <td>497</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-01-02-3</td>\n      <td>269</td>\n      <td>249</td>\n      <td>264</td>\n      <td>261</td>\n      <td>446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-01-02-4</td>\n      <td>269</td>\n      <td>248</td>\n      <td>268</td>\n      <td>266</td>\n      <td>462</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-01-02-5</td>\n      <td>270</td>\n      <td>250</td>\n      <td>269</td>\n      <td>255</td>\n      <td>466</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12495</th>\n      <td>2025-07-01-96</td>\n      <td>113</td>\n      <td>93</td>\n      <td>105</td>\n      <td>107</td>\n      <td>552</td>\n    </tr>\n    <tr>\n      <th>12496</th>\n      <td>2025-07-01-97</td>\n      <td>113</td>\n      <td>93</td>\n      <td>107</td>\n      <td>102</td>\n      <td>532</td>\n    </tr>\n    <tr>\n      <th>12497</th>\n      <td>2025-07-01-98</td>\n      <td>112</td>\n      <td>93</td>\n      <td>93</td>\n      <td>112</td>\n      <td>537</td>\n    </tr>\n    <tr>\n      <th>12498</th>\n      <td>2025-07-01-99</td>\n      <td>112</td>\n      <td>93</td>\n      <td>112</td>\n      <td>107</td>\n      <td>537</td>\n    </tr>\n    <tr>\n      <th>12499</th>\n      <td>2025-07-01-100</td>\n      <td>113</td>\n      <td>98</td>\n      <td>106</td>\n      <td>107</td>\n      <td>678</td>\n    </tr>\n  </tbody>\n</table>\n<p>12500 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始空DataFrame，用于定义列名\n",
    "result_df = pd.DataFrame(columns=['period', 'max_price', 'min_price', 'open_price', 'close_price', 'Volume'])\n",
    "\n",
    "# 用于存储每个文件处理结果的DataFrame列表\n",
    "df_list = []\n",
    "for i in file_ls:\n",
    "    segments_df = detailprice(i)  # 调用detailprice函数处理每个文件\n",
    "    df_list.append(segments_df)  # 将结果添加到列表中\n",
    "# 在循环结束后，一次性拼接所有DataFrame\n",
    "result_df = pd.concat(df_list, axis=0, ignore_index=True)  # 使用ignore_index=True重置索引\n",
    "# 现在 result_df 包含了所有文件处理后的数据，无需再创建新的DataFrame\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "result_df.to_csv(\"E:\\git\\dsmp-2024-group22\\data_preprocess\\DATA\\sperated_tapes_100.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "DatetimeIndex(['2025-01-02', '2025-01-03', '2025-01-06', '2025-01-07',\n               '2025-01-08', '2025-01-09', '2025-01-10', '2025-01-13',\n               '2025-01-14', '2025-01-15',\n               ...\n               '2025-06-18', '2025-06-19', '2025-06-20', '2025-06-23',\n               '2025-06-24', '2025-06-25', '2025-06-26', '2025-06-27',\n               '2025-06-30', '2025-07-01'],\n              dtype='datetime64[ns]', length=125, freq=None)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pattern = r'\\d{4}-\\d{2}-\\d{2}'  # found the date in the file\n",
    "date = []\n",
    "for i in file_ls:\n",
    "    match = re.search(data_pattern, i)\n",
    "    date.append(match.group())\n",
    "date = pd.to_datetime(date)\n",
    "date"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8896/3127121513.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mresults_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfile_ls_series\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mapply_detailprice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mresults_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'max_price'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'min_price'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'open_price'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'close_price'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mdate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\zzyAnaconda\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4431\u001B[0m         \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mfloat64\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4432\u001B[0m         \"\"\"\n\u001B[1;32m-> 4433\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mSeriesApply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconvert_dtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4434\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4435\u001B[0m     def _reduce(\n",
      "\u001B[1;32mD:\\zzyAnaconda\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1080\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1084\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\zzyAnaconda\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1135\u001B[0m                 \u001B[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1136\u001B[0m                 \u001B[1;31m# \"Callable[[Any], Any]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1137\u001B[1;33m                 mapped = lib.map_infer(\n\u001B[0m\u001B[0;32m   1138\u001B[0m                     \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1139\u001B[0m                     \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# type: ignore[arg-type]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\zzyAnaconda\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\zzyAnaconda\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[0;32m    365\u001B[0m             \u001B[0mname\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mibase\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmaybe_extract_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    366\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 367\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mis_empty_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    368\u001B[0m                 \u001B[1;31m# gh-17261\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    369\u001B[0m                 warnings.warn(\n",
      "\u001B[1;32mD:\\zzyAnaconda\\lib\\site-packages\\pandas\\core\\construction.py\u001B[0m in \u001B[0;36mis_empty_data\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    816\u001B[0m     \u001B[0mis_none\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    817\u001B[0m     \u001B[0mis_list_like_without_dtype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mis_list_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"dtype\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 818\u001B[1;33m     \u001B[0mis_simple_empty\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mis_list_like_without_dtype\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    819\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mis_none\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mis_simple_empty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    820\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\zzyAnaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m__nonzero__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1525\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mfinal\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1526\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__nonzero__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1527\u001B[1;33m         raise ValueError(\n\u001B[0m\u001B[0;32m   1528\u001B[0m             \u001B[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1529\u001B[0m             \u001B[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "file_ls_series = pd.Series(file_ls)\n",
    "results_df = []\n",
    "\n",
    "\n",
    "def apply_detailprice(filename):\n",
    "    return detailprice(filename)  # Make sure that this function returns a tuple or list of four values\n",
    "\n",
    "\n",
    "results_df = file_ls_series.apply(apply_detailprice).apply(pd.Series)\n",
    "results_df.columns = ['max_price', 'min_price', 'open_price', 'close_price']\n",
    "date = pd.Series(date)\n",
    "results_df.insert(0, \"date\", date)\n",
    "results_df.head(5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_date, end_date = date.min(), date.max()  # create a new dataframe which have all date in this range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "date_range = pd.Series(date_range)\n",
    "df_full = pd.DataFrame(date_range, columns=['date'])\n",
    "df_full.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_full, results_df, on=\"date\", how=\"left\")  # left join 2 df\n",
    "df_merged.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_3828/4049990813.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf_merged\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"E:/mini project bristol/processed data(LOBS,tapes)/processed_tapes.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'df_merged' is not defined"
     ]
    }
   ],
   "source": [
    "df_merged.to_csv(\"E:/mini project bristol/processed data(LOBS,tapes)/processed_tapes.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}